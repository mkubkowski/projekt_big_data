{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be0d3968-5086-4674-ad88-d463b113c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from gensim.corpora import Dictionary\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import boto3\n",
    "import pickle\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e757693-6186-4f78-af63-a6e26a3b55f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab0cbb6-a423-47bd-9721-5a2a228391c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "response = s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc7d2fc-6980-4d10-99f1-0e682f4d21db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '04RGGCJBSXP8DY3A',\n",
       "  'HostId': '6qJr0UGjNLHPEcR27PVWRbUzVGXKlrNrXkVfRn52ldqp/fS/1FlYu1vMLPS1P9EwdBHVea1JS3c=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '6qJr0UGjNLHPEcR27PVWRbUzVGXKlrNrXkVfRn52ldqp/fS/1FlYu1vMLPS1P9EwdBHVea1JS3c=',\n",
       "   'x-amz-request-id': '04RGGCJBSXP8DY3A',\n",
       "   'date': 'Sun, 21 Jan 2024 10:04:13 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'aws-glue-assets-000104845890-us-east-1',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 17, 9, 50, 30, tzinfo=tzlocal())},\n",
       "  {'Name': 'aws-logs-000104845890-us-east-1',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 17, 17, 53, 43, tzinfo=tzlocal())},\n",
       "  {'Name': 'bucket-athena-results-17012024',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 17, 17, 27, 17, tzinfo=tzlocal())},\n",
       "  {'Name': 'bucket-flink-18012024',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 18, 20, 16, 10, tzinfo=tzlocal())},\n",
       "  {'Name': 'bucket-formatted-data-17012024',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 17, 8, 45, 6, tzinfo=tzlocal())},\n",
       "  {'Name': 'bucket-raw-data16012024',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 16, 11, 5, 24, tzinfo=tzlocal())},\n",
       "  {'Name': 'bucket-sparkapp-17012024',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 17, 17, 55, 41, tzinfo=tzlocal())},\n",
       "  {'Name': 'spark-results-17012024',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 17, 17, 57, 7, tzinfo=tzlocal())}],\n",
       " 'Owner': {'DisplayName': 'awslabsc0w5526977t1680220615',\n",
       "  'ID': '2b1219a628bd6dd1359ef462f126229e4a6114704079943aa744ef8dc0d9d493'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "553306e8-ec15-46be-a113-7e7a71f54716",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "obj = s3.Object(bucket_name='bucket-raw-data16012024', key='part-01.json')\n",
    "response = obj.get()\n",
    "data = response['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "989014ed-f846-4a7e-a403-782c1de1f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_test = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a670acb1-92cf-4eaa-b826-7bdd39ca1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = pd.DataFrame(json_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c829c5-4444-4379-ac21-337a48eec1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review_date</th>\n",
       "      <th>spoiler_tag</th>\n",
       "      <th>review_detail</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rw5704482</td>\n",
       "      <td>raeldor-96879</td>\n",
       "      <td>After Life (2019– )</td>\n",
       "      <td>9</td>\n",
       "      <td>Very Strong Season 2</td>\n",
       "      <td>3 May 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>I enjoyed the first season, but I must say I t...</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rw5704483</td>\n",
       "      <td>dosleeb</td>\n",
       "      <td>The Valhalla Murders (2019– )</td>\n",
       "      <td>6</td>\n",
       "      <td>Icelandic detectives?</td>\n",
       "      <td>3 May 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>I know Iceland is a small country and police d...</td>\n",
       "      <td>[2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rw5704484</td>\n",
       "      <td>brightconscious</td>\n",
       "      <td>Special OPS (2020– )</td>\n",
       "      <td>7</td>\n",
       "      <td>Nothing special</td>\n",
       "      <td>3 May 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>Except K K , no other actor looks comfortable ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rw5704485</td>\n",
       "      <td>gasconyway</td>\n",
       "      <td>#BlackAF (2020– )</td>\n",
       "      <td>8</td>\n",
       "      <td>Good but</td>\n",
       "      <td>3 May 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm guessing that as a 62 year old white woman...</td>\n",
       "      <td>[5, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rw5704487</td>\n",
       "      <td>mmason-15867</td>\n",
       "      <td>The Droving (2020)</td>\n",
       "      <td>2</td>\n",
       "      <td>An honest review</td>\n",
       "      <td>3 May 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>Here's the truth. There's not much to this mov...</td>\n",
       "      <td>[26, 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010288</th>\n",
       "      <td>rw0982994</td>\n",
       "      <td>backseat-2</td>\n",
       "      <td>Flight of the Phoenix (2004)</td>\n",
       "      <td>3</td>\n",
       "      <td>What a waste</td>\n",
       "      <td>21 December 2004</td>\n",
       "      <td>1</td>\n",
       "      <td>The original Flight of the Phoenix is a classi...</td>\n",
       "      <td>[16, 31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010289</th>\n",
       "      <td>rw0982996</td>\n",
       "      <td>Sunshine95</td>\n",
       "      <td>A Series of Unfortunate Events (2004)</td>\n",
       "      <td>10</td>\n",
       "      <td>Lots of Comedy</td>\n",
       "      <td>21 December 2004</td>\n",
       "      <td>1</td>\n",
       "      <td>Lemony Snickets was a Great movie because of t...</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010290</th>\n",
       "      <td>rw0982997</td>\n",
       "      <td>ComeAsYouAre91</td>\n",
       "      <td>The Matrix (1999)</td>\n",
       "      <td>8</td>\n",
       "      <td>Why Hate It???</td>\n",
       "      <td>21 December 2004</td>\n",
       "      <td>0</td>\n",
       "      <td>When The Matrix came out I was only twelve yea...</td>\n",
       "      <td>[1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010291</th>\n",
       "      <td>rw0982998</td>\n",
       "      <td>skyymelonpeace44-1</td>\n",
       "      <td>Elf (2003)</td>\n",
       "      <td>8</td>\n",
       "      <td>Best Christmas movie for kids</td>\n",
       "      <td>21 December 2004</td>\n",
       "      <td>0</td>\n",
       "      <td>I think the movie was really good.Its a kids m...</td>\n",
       "      <td>[1, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010292</th>\n",
       "      <td>rw0982999</td>\n",
       "      <td>katiedamien</td>\n",
       "      <td>House M.D. (2004–2012)</td>\n",
       "      <td>None</td>\n",
       "      <td>House is great entertainment</td>\n",
       "      <td>21 December 2004</td>\n",
       "      <td>0</td>\n",
       "      <td>My mother and I watch House religiously. Of co...</td>\n",
       "      <td>[8, 12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010293 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         review_id            reviewer                                  movie  \\\n",
       "0        rw5704482       raeldor-96879                    After Life (2019– )   \n",
       "1        rw5704483             dosleeb          The Valhalla Murders (2019– )   \n",
       "2        rw5704484     brightconscious                   Special OPS (2020– )   \n",
       "3        rw5704485          gasconyway                      #BlackAF (2020– )   \n",
       "4        rw5704487        mmason-15867                     The Droving (2020)   \n",
       "...            ...                 ...                                    ...   \n",
       "1010288  rw0982994          backseat-2           Flight of the Phoenix (2004)   \n",
       "1010289  rw0982996          Sunshine95  A Series of Unfortunate Events (2004)   \n",
       "1010290  rw0982997      ComeAsYouAre91                      The Matrix (1999)   \n",
       "1010291  rw0982998  skyymelonpeace44-1                             Elf (2003)   \n",
       "1010292  rw0982999         katiedamien                 House M.D. (2004–2012)   \n",
       "\n",
       "        rating                 review_summary       review_date  spoiler_tag  \\\n",
       "0            9           Very Strong Season 2        3 May 2020            0   \n",
       "1            6          Icelandic detectives?        3 May 2020            0   \n",
       "2            7                Nothing special        3 May 2020            0   \n",
       "3            8                       Good but        3 May 2020            0   \n",
       "4            2               An honest review        3 May 2020            0   \n",
       "...        ...                            ...               ...          ...   \n",
       "1010288      3                   What a waste  21 December 2004            1   \n",
       "1010289     10                 Lots of Comedy  21 December 2004            1   \n",
       "1010290      8                 Why Hate It???  21 December 2004            0   \n",
       "1010291      8  Best Christmas movie for kids  21 December 2004            0   \n",
       "1010292   None   House is great entertainment  21 December 2004            0   \n",
       "\n",
       "                                             review_detail   helpful  \n",
       "0        I enjoyed the first season, but I must say I t...    [1, 1]  \n",
       "1        I know Iceland is a small country and police d...    [2, 2]  \n",
       "2        Except K K , no other actor looks comfortable ...    [0, 0]  \n",
       "3        I'm guessing that as a 62 year old white woman...    [5, 9]  \n",
       "4        Here's the truth. There's not much to this mov...  [26, 41]  \n",
       "...                                                    ...       ...  \n",
       "1010288  The original Flight of the Phoenix is a classi...  [16, 31]  \n",
       "1010289  Lemony Snickets was a Great movie because of t...    [2, 3]  \n",
       "1010290  When The Matrix came out I was only twelve yea...    [1, 3]  \n",
       "1010291  I think the movie was really good.Its a kids m...    [1, 4]  \n",
       "1010292  My mother and I watch House religiously. Of co...   [8, 12]  \n",
       "\n",
       "[1010293 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d3fcf50-1eb9-4603-9a26-a4f5f167fc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id         object\n",
       "reviewer          object\n",
       "movie             object\n",
       "rating            object\n",
       "review_summary    object\n",
       "review_date       object\n",
       "spoiler_tag        int64\n",
       "review_detail     object\n",
       "helpful           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97d30060-4dec-47bf-9c80-034ff8907d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id             0\n",
       "reviewer              0\n",
       "movie                 0\n",
       "rating            51520\n",
       "review_summary        0\n",
       "review_date           0\n",
       "spoiler_tag           0\n",
       "review_detail         0\n",
       "helpful               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d098e421-ad1a-43ab-9dbb-f17c77fe4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd1 = df_pd.copy()\n",
    "df_pd1['rating'] = df_pd['rating'].fillna(np.nan).astype('float64')\n",
    "df_pd1['helpful_0'] = df_pd['helpful'].apply(lambda x: x[0]).str.replace(\",\",\"\").astype('int64')\n",
    "df_pd1['helpful_1'] = df_pd['helpful'].apply(lambda x: x[1]).str.replace(\",\",\"\").astype('int64')\n",
    "df_pd1['helpful_perc'] = df_pd1['helpful_0']/df_pd1['helpful_1']\n",
    "df_pd1['review_dt'] = pd.to_datetime(df_pd['review_date'],format=\"%d %B %Y\")\n",
    "df_pd1['review_year'] = df_pd1['review_dt'].dt.to_period('Y')\n",
    "df_pd1['review_month'] = df_pd1['review_dt'].dt.to_period('M')\n",
    "df_pd1['movie_year'] = df_pd['movie'].str.extract(r\"\\((\\d+[^\\)]*)\\)[^\\(]*$\",expand=False).str.extract(r\"(\\d+)\",expand=False).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b637ccd4-1d32-4c4d-8b8c-b9d46d64bb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review_date</th>\n",
       "      <th>spoiler_tag</th>\n",
       "      <th>review_detail</th>\n",
       "      <th>helpful</th>\n",
       "      <th>helpful_0</th>\n",
       "      <th>helpful_1</th>\n",
       "      <th>helpful_perc</th>\n",
       "      <th>review_dt</th>\n",
       "      <th>review_year</th>\n",
       "      <th>review_month</th>\n",
       "      <th>movie_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rw5704482</td>\n",
       "      <td>raeldor-96879</td>\n",
       "      <td>After Life (2019– )</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Very Strong Season 2</td>\n",
       "      <td>3 May 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>I enjoyed the first season, but I must say I t...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-05</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rw5704483</td>\n",
       "      <td>dosleeb</td>\n",
       "      <td>The Valhalla Murders (2019– )</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Icelandic detectives?</td>\n",
       "      <td>3 May 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>I know Iceland is a small country and police d...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-05</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rw5704484</td>\n",
       "      <td>brightconscious</td>\n",
       "      <td>Special OPS (2020– )</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Nothing special</td>\n",
       "      <td>3 May 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>Except K K , no other actor looks comfortable ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-05</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rw5704485</td>\n",
       "      <td>gasconyway</td>\n",
       "      <td>#BlackAF (2020– )</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Good but</td>\n",
       "      <td>3 May 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm guessing that as a 62 year old white woman...</td>\n",
       "      <td>[5, 9]</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-05</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rw5704487</td>\n",
       "      <td>mmason-15867</td>\n",
       "      <td>The Droving (2020)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>An honest review</td>\n",
       "      <td>3 May 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>Here's the truth. There's not much to this mov...</td>\n",
       "      <td>[26, 41]</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-05</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id         reviewer                          movie  rating  \\\n",
       "0  rw5704482    raeldor-96879            After Life (2019– )     9.0   \n",
       "1  rw5704483          dosleeb  The Valhalla Murders (2019– )     6.0   \n",
       "2  rw5704484  brightconscious           Special OPS (2020– )     7.0   \n",
       "3  rw5704485       gasconyway              #BlackAF (2020– )     8.0   \n",
       "4  rw5704487     mmason-15867             The Droving (2020)     2.0   \n",
       "\n",
       "          review_summary review_date  spoiler_tag  \\\n",
       "0   Very Strong Season 2  3 May 2020            0   \n",
       "1  Icelandic detectives?  3 May 2020            0   \n",
       "2        Nothing special  3 May 2020            0   \n",
       "3               Good but  3 May 2020            0   \n",
       "4       An honest review  3 May 2020            0   \n",
       "\n",
       "                                       review_detail   helpful  helpful_0  \\\n",
       "0  I enjoyed the first season, but I must say I t...    [1, 1]          1   \n",
       "1  I know Iceland is a small country and police d...    [2, 2]          2   \n",
       "2  Except K K , no other actor looks comfortable ...    [0, 0]          0   \n",
       "3  I'm guessing that as a 62 year old white woman...    [5, 9]          5   \n",
       "4  Here's the truth. There's not much to this mov...  [26, 41]         26   \n",
       "\n",
       "   helpful_1  helpful_perc  review_dt review_year review_month  movie_year  \n",
       "0          1      1.000000 2020-05-03        2020      2020-05      2019.0  \n",
       "1          2      1.000000 2020-05-03        2020      2020-05      2019.0  \n",
       "2          0           NaN 2020-05-03        2020      2020-05      2020.0  \n",
       "3          9      0.555556 2020-05-03        2020      2020-05      2020.0  \n",
       "4         41      0.634146 2020-05-03        2020      2020-05      2020.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd42595-b1d4-4d1d-8f7c-cd79396d2f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id                 object\n",
       "reviewer                  object\n",
       "movie                     object\n",
       "rating                   float64\n",
       "review_summary            object\n",
       "review_date               object\n",
       "spoiler_tag                int64\n",
       "review_detail             object\n",
       "helpful                   object\n",
       "helpful_0                  int64\n",
       "helpful_1                  int64\n",
       "helpful_perc             float64\n",
       "review_dt         datetime64[ns]\n",
       "review_year        period[A-DEC]\n",
       "review_month           period[M]\n",
       "movie_year               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc54c0-4d99-4b08-883e-41117cc94774",
   "metadata": {},
   "source": [
    "### Przygotowujemy słownik do mapowania tokenów na liczby naturalne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2086e3c2-6fd7-4a87-8574-15d10eec18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_in_dataset = 5000\n",
    "document_max_len = 400\n",
    "batch_size0 = 10000\n",
    "batch_size = 32\n",
    "embedding_dim = 64\n",
    "\n",
    "punc = string.punctuation\n",
    "dct = Dictionary()\n",
    "\n",
    "def wt(string):\n",
    "    return [w.lower() for w in word_tokenize(string)\n",
    "                if w.lower() not in punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59cb5f66-afc3-4cad-b3d5-61fc1d263170",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_pd1['review_detail']\n",
    "y = df_pd1['spoiler_tag']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a02e95f5-bc72-4c45-8087-70d43018d1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157926    0\n",
       "634635    0\n",
       "226955    0\n",
       "748172    0\n",
       "118159    0\n",
       "         ..\n",
       "564465    0\n",
       "412925    0\n",
       "255366    0\n",
       "759451    0\n",
       "472907    0\n",
       "Name: spoiler_tag, Length: 707205, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a119e2e3-ae03-4dd4-8ff5-7948d05810eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = 'processed_batches/'\n",
    "path_out_x_train = path_out + 'x_train/'\n",
    "path_out_y_train = path_out + 'y_train/'\n",
    "path_out_x_test = path_out + 'x_test/'\n",
    "path_out_y_test = path_out + 'y_test/'\n",
    "\n",
    "if not(os.path.exists(path_out)):\n",
    "    os.mkdir(path_out)\n",
    "if not(os.path.exists(path_out_x_train)):\n",
    "    os.mkdir(path_out_x_train)\n",
    "if not(os.path.exists(path_out_y_train)):\n",
    "    os.mkdir(path_out_y_train)\n",
    "if not(os.path.exists(path_out_x_test)):\n",
    "    os.mkdir(path_out_x_test)\n",
    "if not(os.path.exists(path_out_y_test)):\n",
    "    os.mkdir(path_out_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36294ec8-e86f-481a-a184-5bf84977d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch_size,batch_i,data_x,data_y,dct,output_loc_x,output_loc_y):\n",
    "    x_batch = data_x.iloc[(batch_i*batch_size):((batch_i+1)*batch_size)]\n",
    "    y_batch = data_y.iloc[(batch_i*batch_size):((batch_i+1)*batch_size)]\n",
    "    review_detail_clear = x_batch.apply(wt)\n",
    "    dct.add_documents(review_detail_clear)\n",
    "    review_detail_idx = review_detail_clear.apply(lambda x: [y%tokens_in_dataset \n",
    "                                                         for y in dct.doc2idx(x)])\n",
    "    padded_seq = sequence.pad_sequences(review_detail_idx, maxlen=document_max_len, padding='pre', truncating='post')\n",
    "    with open(f\"{output_loc_x}x_{batch_i}.pickle\",\"wb\") as f:\n",
    "        pickle.dump(padded_seq,f)\n",
    "    with open(f\"{output_loc_y}y_{batch_i}.pickle\",\"wb\") as f:\n",
    "        pickle.dump(y_batch,f)\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22bb881b-9911-4e70-a25b-e62b184e3d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-21 11:22:15.766395 Processing training set - batch 1/71\n",
      "2024-01-21 11:22:23.542516 Processing training set - batch 2/71\n",
      "2024-01-21 11:22:31.203230 Processing training set - batch 3/71\n",
      "2024-01-21 11:22:38.813810 Processing training set - batch 4/71\n",
      "2024-01-21 11:22:46.460788 Processing training set - batch 5/71\n",
      "2024-01-21 11:22:54.177838 Processing training set - batch 6/71\n",
      "2024-01-21 11:23:01.921906 Processing training set - batch 7/71\n",
      "2024-01-21 11:23:09.665118 Processing training set - batch 8/71\n",
      "2024-01-21 11:23:17.504796 Processing training set - batch 9/71\n",
      "2024-01-21 11:23:25.193860 Processing training set - batch 10/71\n",
      "2024-01-21 11:23:33.018410 Processing training set - batch 11/71\n",
      "2024-01-21 11:23:40.680662 Processing training set - batch 12/71\n",
      "2024-01-21 11:23:48.549336 Processing training set - batch 13/71\n",
      "2024-01-21 11:23:57.344330 Processing training set - batch 14/71\n",
      "2024-01-21 11:24:05.042289 Processing training set - batch 15/71\n",
      "2024-01-21 11:24:12.716561 Processing training set - batch 16/71\n",
      "2024-01-21 11:24:20.341591 Processing training set - batch 17/71\n",
      "2024-01-21 11:24:28.046011 Processing training set - batch 18/71\n",
      "2024-01-21 11:24:35.851565 Processing training set - batch 19/71\n",
      "2024-01-21 11:24:43.713387 Processing training set - batch 20/71\n",
      "2024-01-21 11:24:51.453467 Processing training set - batch 21/71\n",
      "2024-01-21 11:24:59.211702 Processing training set - batch 22/71\n",
      "2024-01-21 11:25:06.987222 Processing training set - batch 23/71\n",
      "2024-01-21 11:25:14.776744 Processing training set - batch 24/71\n",
      "2024-01-21 11:25:22.696855 Processing training set - batch 25/71\n",
      "2024-01-21 11:25:30.657758 Processing training set - batch 26/71\n",
      "2024-01-21 11:25:38.323093 Processing training set - batch 27/71\n",
      "2024-01-21 11:25:46.221518 Processing training set - batch 28/71\n",
      "2024-01-21 11:25:54.051435 Processing training set - batch 29/71\n",
      "2024-01-21 11:26:01.960880 Processing training set - batch 30/71\n",
      "2024-01-21 11:26:09.775031 Processing training set - batch 31/71\n",
      "2024-01-21 11:26:17.613974 Processing training set - batch 32/71\n",
      "2024-01-21 11:26:25.557022 Processing training set - batch 33/71\n",
      "2024-01-21 11:26:33.345195 Processing training set - batch 34/71\n",
      "2024-01-21 11:26:41.055708 Processing training set - batch 35/71\n",
      "2024-01-21 11:26:48.831625 Processing training set - batch 36/71\n",
      "2024-01-21 11:26:56.572889 Processing training set - batch 37/71\n",
      "2024-01-21 11:27:04.386358 Processing training set - batch 38/71\n",
      "2024-01-21 11:27:12.207459 Processing training set - batch 39/71\n",
      "2024-01-21 11:27:19.944536 Processing training set - batch 40/71\n",
      "2024-01-21 11:27:27.684116 Processing training set - batch 41/71\n",
      "2024-01-21 11:27:35.387550 Processing training set - batch 42/71\n",
      "2024-01-21 11:27:43.228125 Processing training set - batch 43/71\n",
      "2024-01-21 11:27:51.200269 Processing training set - batch 44/71\n",
      "2024-01-21 11:27:59.249436 Processing training set - batch 45/71\n",
      "2024-01-21 11:28:07.160464 Processing training set - batch 46/71\n",
      "2024-01-21 11:28:15.120063 Processing training set - batch 47/71\n",
      "2024-01-21 11:28:23.099428 Processing training set - batch 48/71\n",
      "2024-01-21 11:28:31.194046 Processing training set - batch 49/71\n",
      "2024-01-21 11:28:39.240780 Processing training set - batch 50/71\n",
      "2024-01-21 11:28:47.166594 Processing training set - batch 51/71\n",
      "2024-01-21 11:28:55.026214 Processing training set - batch 52/71\n",
      "2024-01-21 11:29:02.830730 Processing training set - batch 53/71\n",
      "2024-01-21 11:29:10.816504 Processing training set - batch 54/71\n",
      "2024-01-21 11:29:18.766055 Processing training set - batch 55/71\n",
      "2024-01-21 11:29:26.859010 Processing training set - batch 56/71\n",
      "2024-01-21 11:29:34.890828 Processing training set - batch 57/71\n",
      "2024-01-21 11:29:42.789814 Processing training set - batch 58/71\n",
      "2024-01-21 11:29:51.508506 Processing training set - batch 59/71\n",
      "2024-01-21 11:29:59.417186 Processing training set - batch 60/71\n",
      "2024-01-21 11:30:07.485740 Processing training set - batch 61/71\n",
      "2024-01-21 11:30:15.450213 Processing training set - batch 62/71\n",
      "2024-01-21 11:30:23.370931 Processing training set - batch 63/71\n",
      "2024-01-21 11:30:31.050076 Processing training set - batch 64/71\n",
      "2024-01-21 11:30:38.938536 Processing training set - batch 65/71\n",
      "2024-01-21 11:30:46.652934 Processing training set - batch 66/71\n",
      "2024-01-21 11:30:54.496672 Processing training set - batch 67/71\n",
      "2024-01-21 11:31:02.322394 Processing training set - batch 68/71\n",
      "2024-01-21 11:31:10.185996 Processing training set - batch 69/71\n",
      "2024-01-21 11:31:17.939769 Processing training set - batch 70/71\n",
      "2024-01-21 11:31:25.822099 Processing training set - batch 71/71\n",
      "2024-01-21 11:31:31.462241 Processing test set - batch 1/31\n",
      "2024-01-21 11:31:39.314468 Processing test set - batch 2/31\n",
      "2024-01-21 11:31:47.079230 Processing test set - batch 3/31\n",
      "2024-01-21 11:31:54.959652 Processing test set - batch 4/31\n",
      "2024-01-21 11:32:02.912999 Processing test set - batch 5/31\n",
      "2024-01-21 11:32:10.816866 Processing test set - batch 6/31\n",
      "2024-01-21 11:32:18.734553 Processing test set - batch 7/31\n",
      "2024-01-21 11:32:26.652083 Processing test set - batch 8/31\n",
      "2024-01-21 11:32:34.529231 Processing test set - batch 9/31\n",
      "2024-01-21 11:32:42.336592 Processing test set - batch 10/31\n",
      "2024-01-21 11:32:50.215046 Processing test set - batch 11/31\n",
      "2024-01-21 11:32:58.076595 Processing test set - batch 12/31\n",
      "2024-01-21 11:33:05.885080 Processing test set - batch 13/31\n",
      "2024-01-21 11:33:13.672727 Processing test set - batch 14/31\n",
      "2024-01-21 11:33:21.401732 Processing test set - batch 15/31\n",
      "2024-01-21 11:33:29.248066 Processing test set - batch 16/31\n",
      "2024-01-21 11:33:37.059352 Processing test set - batch 17/31\n",
      "2024-01-21 11:33:44.907285 Processing test set - batch 18/31\n",
      "2024-01-21 11:33:52.770415 Processing test set - batch 19/31\n",
      "2024-01-21 11:34:00.715140 Processing test set - batch 20/31\n",
      "2024-01-21 11:34:08.466398 Processing test set - batch 21/31\n",
      "2024-01-21 11:34:16.382186 Processing test set - batch 22/31\n",
      "2024-01-21 11:34:24.296403 Processing test set - batch 23/31\n",
      "2024-01-21 11:34:32.178579 Processing test set - batch 24/31\n",
      "2024-01-21 11:34:40.185836 Processing test set - batch 25/31\n",
      "2024-01-21 11:34:47.973171 Processing test set - batch 26/31\n",
      "2024-01-21 11:34:55.771295 Processing test set - batch 27/31\n",
      "2024-01-21 11:35:03.636572 Processing test set - batch 28/31\n",
      "2024-01-21 11:35:12.302485 Processing test set - batch 29/31\n",
      "2024-01-21 11:35:20.140217 Processing test set - batch 30/31\n",
      "2024-01-21 11:35:27.861476 Processing test set - batch 31/31\n"
     ]
    }
   ],
   "source": [
    "n_batch0_train = int(np.ceil(x_train.shape[0]/batch_size0))\n",
    "\n",
    "for i in range(n_batch0_train):\n",
    "    print(f\"{datetime.datetime.now()} Processing training set - batch {i+1}/{n_batch0_train}\")\n",
    "    dct = preprocess_batch(batch_size0,i,x_train,y_train,dct,path_out_x_train,path_out_y_train)\n",
    "\n",
    "n_batch0_test = int(np.ceil(x_test.shape[0]/batch_size0))\n",
    "\n",
    "for i in range(n_batch0_test):\n",
    "    print(f\"{datetime.datetime.now()} Processing test set - batch {i+1}/{n_batch0_test}\")\n",
    "    dct = preprocess_batch(batch_size0,i,x_test,y_test,dct,path_out_x_test,path_out_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab376da1-76fb-42d6-8a00-dd001f3acec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 12:07:45.378886: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-01-21 12:07:45.380307: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-01-21 12:07:45.380327: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-91-7): /proc/driver/nvidia/version does not exist\n",
      "2024-01-21 12:07:45.381955: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 400, 64)           320000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 400, 32)           12416     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 335,841\n",
      "Trainable params: 335,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=tokens_in_dataset, # liczba unikalnych tokenów\n",
    "                    output_dim=embedding_dim, # wielkość embeddingu\n",
    "                    input_length=document_max_len, # długość sekwencji\n",
    "                    ))\n",
    "model.add(LSTM(units=32, activation='tanh', return_sequences=True))\n",
    "model.add(LSTM(units=16, activation='tanh', return_sequences=False))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(patience=3, monitor='val_loss')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1ebaa34-05b6-4fed-976a-4bd6d9d11e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2024-01-21 12:19:20.346789 Training - batch 1/71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/my_env/lib/python3.10/site-packages/keras/engine/data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 37s 140ms/step - loss: 0.4990 - accuracy: 0.8090 - val_loss: 0.4859 - val_accuracy: 0.8100\n",
      "2024-01-21 12:19:57.342603 Training - batch 2/71\n",
      "250/250 [==============================] - 35s 138ms/step - loss: 0.4770 - accuracy: 0.8130 - val_loss: 0.4685 - val_accuracy: 0.8160\n",
      "2024-01-21 12:20:31.943114 Training - batch 3/71\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.4566 - accuracy: 0.8189 - val_loss: 0.4241 - val_accuracy: 0.8225\n",
      "2024-01-21 12:21:06.822713 Training - batch 4/71\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.4669 - accuracy: 0.8071 - val_loss: 0.4473 - val_accuracy: 0.7995\n",
      "2024-01-21 12:21:41.578057 Training - batch 5/71\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.4579 - accuracy: 0.8081 - val_loss: 0.4283 - val_accuracy: 0.8210\n",
      "2024-01-21 12:22:16.289422 Training - batch 6/71\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.4276 - accuracy: 0.8152 - val_loss: 0.4254 - val_accuracy: 0.8120\n",
      "2024-01-21 12:22:51.037577 Training - batch 7/71\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.4234 - accuracy: 0.8112 - val_loss: 0.3987 - val_accuracy: 0.8255\n",
      "2024-01-21 12:23:25.832597 Training - batch 8/71\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.4248 - accuracy: 0.8124 - val_loss: 0.4083 - val_accuracy: 0.8210\n",
      "2024-01-21 12:24:00.791908 Training - batch 9/71\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.4199 - accuracy: 0.8164 - val_loss: 0.4223 - val_accuracy: 0.8185\n",
      "2024-01-21 12:24:35.522585 Training - batch 10/71\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.4113 - accuracy: 0.8205 - val_loss: 0.4115 - val_accuracy: 0.8215\n",
      "2024-01-21 12:25:10.451278 Training - batch 11/71\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.4121 - accuracy: 0.8185 - val_loss: 0.3866 - val_accuracy: 0.8285\n",
      "2024-01-21 12:25:45.439250 Training - batch 12/71\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.4109 - accuracy: 0.8254 - val_loss: 0.4226 - val_accuracy: 0.8070\n",
      "2024-01-21 12:26:20.587796 Training - batch 13/71\n",
      "250/250 [==============================] - 35s 141ms/step - loss: 0.4188 - accuracy: 0.8139 - val_loss: 0.3970 - val_accuracy: 0.8110\n",
      "2024-01-21 12:26:55.813549 Training - batch 14/71\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.3974 - accuracy: 0.8264 - val_loss: 0.4077 - val_accuracy: 0.8260\n",
      "2024-01-21 12:27:30.907255 Training - batch 15/71\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.4023 - accuracy: 0.8235 - val_loss: 0.4046 - val_accuracy: 0.8325\n",
      "2024-01-21 12:28:05.963492 Training - batch 16/71\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.4057 - accuracy: 0.8217 - val_loss: 0.3980 - val_accuracy: 0.8275\n",
      "2024-01-21 12:28:40.986655 Training - batch 17/71\n",
      "250/250 [==============================] - 35s 141ms/step - loss: 0.3973 - accuracy: 0.8322 - val_loss: 0.4130 - val_accuracy: 0.8220\n",
      "2024-01-21 12:29:16.245541 Training - batch 18/71\n",
      "250/250 [==============================] - 35s 142ms/step - loss: 0.4153 - accuracy: 0.8202 - val_loss: 0.3843 - val_accuracy: 0.8480\n",
      "2024-01-21 12:29:51.720727 Training - batch 19/71\n",
      "250/250 [==============================] - 35s 142ms/step - loss: 0.4160 - accuracy: 0.8181 - val_loss: 0.3961 - val_accuracy: 0.8330\n",
      "2024-01-21 12:30:27.132585 Training - batch 20/71\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.4094 - accuracy: 0.8223 - val_loss: 0.4200 - val_accuracy: 0.8160\n",
      "2024-01-21 12:31:02.734029 Training - batch 21/71\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.4077 - accuracy: 0.8234 - val_loss: 0.3952 - val_accuracy: 0.8340\n",
      "2024-01-21 12:31:38.340587 Training - batch 22/71\n",
      "250/250 [==============================] - 35s 142ms/step - loss: 0.3986 - accuracy: 0.8265 - val_loss: 0.3926 - val_accuracy: 0.8310\n",
      "2024-01-21 12:32:13.830863 Training - batch 23/71\n",
      "250/250 [==============================] - 35s 142ms/step - loss: 0.3957 - accuracy: 0.8303 - val_loss: 0.3946 - val_accuracy: 0.8320\n",
      "2024-01-21 12:32:49.353351 Training - batch 24/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3962 - accuracy: 0.8304 - val_loss: 0.4000 - val_accuracy: 0.8320\n",
      "2024-01-21 12:33:25.141161 Training - batch 25/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.4048 - accuracy: 0.8259 - val_loss: 0.3951 - val_accuracy: 0.8200\n",
      "2024-01-21 12:34:01.046171 Training - batch 26/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3855 - accuracy: 0.8356 - val_loss: 0.4016 - val_accuracy: 0.8250\n",
      "2024-01-21 12:34:36.910677 Training - batch 27/71\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.3999 - accuracy: 0.8314 - val_loss: 0.3863 - val_accuracy: 0.8330\n",
      "2024-01-21 12:35:12.512085 Training - batch 28/71\n",
      "250/250 [==============================] - 35s 142ms/step - loss: 0.3854 - accuracy: 0.8381 - val_loss: 0.3946 - val_accuracy: 0.8255\n",
      "2024-01-21 12:35:47.929568 Training - batch 29/71\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.3927 - accuracy: 0.8282 - val_loss: 0.3858 - val_accuracy: 0.8465\n",
      "2024-01-21 12:36:23.489037 Training - batch 30/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.4005 - accuracy: 0.8341 - val_loss: 0.3956 - val_accuracy: 0.8320\n",
      "2024-01-21 12:36:59.294852 Training - batch 31/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3823 - accuracy: 0.8414 - val_loss: 0.4121 - val_accuracy: 0.8110\n",
      "2024-01-21 12:37:34.968583 Training - batch 32/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3937 - accuracy: 0.8349 - val_loss: 0.3896 - val_accuracy: 0.8385\n",
      "2024-01-21 12:38:10.676484 Training - batch 33/71\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.4018 - accuracy: 0.8257 - val_loss: 0.3857 - val_accuracy: 0.8435\n",
      "2024-01-21 12:38:46.308820 Training - batch 34/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3974 - accuracy: 0.8345 - val_loss: 0.4126 - val_accuracy: 0.8170\n",
      "2024-01-21 12:39:22.149161 Training - batch 35/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.4027 - accuracy: 0.8245 - val_loss: 0.3958 - val_accuracy: 0.8245\n",
      "2024-01-21 12:39:57.864939 Training - batch 36/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3805 - accuracy: 0.8386 - val_loss: 0.3859 - val_accuracy: 0.8320\n",
      "2024-01-21 12:40:33.616595 Training - batch 37/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3892 - accuracy: 0.8322 - val_loss: 0.3916 - val_accuracy: 0.8265\n",
      "2024-01-21 12:41:09.319418 Training - batch 38/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3840 - accuracy: 0.8346 - val_loss: 0.4116 - val_accuracy: 0.8185\n",
      "2024-01-21 12:41:45.210528 Training - batch 39/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3957 - accuracy: 0.8314 - val_loss: 0.4053 - val_accuracy: 0.8305\n",
      "2024-01-21 12:42:21.007525 Training - batch 40/71\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.3861 - accuracy: 0.8369 - val_loss: 0.4020 - val_accuracy: 0.8245\n",
      "2024-01-21 12:42:56.651755 Training - batch 41/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3789 - accuracy: 0.8369 - val_loss: 0.3911 - val_accuracy: 0.8350\n",
      "2024-01-21 12:43:32.388236 Training - batch 42/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3858 - accuracy: 0.8364 - val_loss: 0.4127 - val_accuracy: 0.8175\n",
      "2024-01-21 12:44:08.503475 Training - batch 43/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.4063 - accuracy: 0.8235 - val_loss: 0.4072 - val_accuracy: 0.8215\n",
      "2024-01-21 12:44:44.302728 Training - batch 44/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3885 - accuracy: 0.8332 - val_loss: 0.3970 - val_accuracy: 0.8320\n",
      "2024-01-21 12:45:20.203918 Training - batch 45/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3986 - accuracy: 0.8284 - val_loss: 0.3849 - val_accuracy: 0.8380\n",
      "2024-01-21 12:45:56.165065 Training - batch 46/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3860 - accuracy: 0.8341 - val_loss: 0.4000 - val_accuracy: 0.8375\n",
      "2024-01-21 12:46:32.177127 Training - batch 47/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3970 - accuracy: 0.8329 - val_loss: 0.3873 - val_accuracy: 0.8325\n",
      "2024-01-21 12:47:08.214646 Training - batch 48/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.4004 - accuracy: 0.8271 - val_loss: 0.3802 - val_accuracy: 0.8310\n",
      "2024-01-21 12:47:44.157012 Training - batch 49/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3760 - accuracy: 0.8407 - val_loss: 0.4047 - val_accuracy: 0.8275\n",
      "2024-01-21 12:48:19.974443 Training - batch 50/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3972 - accuracy: 0.8298 - val_loss: 0.3872 - val_accuracy: 0.8290\n",
      "2024-01-21 12:48:55.898501 Training - batch 51/71\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.3896 - accuracy: 0.8292 - val_loss: 0.3739 - val_accuracy: 0.8375\n",
      "2024-01-21 12:49:31.695237 Training - batch 52/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3894 - accuracy: 0.8359 - val_loss: 0.3979 - val_accuracy: 0.8250\n",
      "2024-01-21 12:50:07.620497 Training - batch 53/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3889 - accuracy: 0.8350 - val_loss: 0.3773 - val_accuracy: 0.8390\n",
      "2024-01-21 12:50:43.565316 Training - batch 54/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3879 - accuracy: 0.8360 - val_loss: 0.3752 - val_accuracy: 0.8440\n",
      "2024-01-21 12:51:19.526000 Training - batch 55/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3816 - accuracy: 0.8397 - val_loss: 0.4036 - val_accuracy: 0.8220\n",
      "2024-01-21 12:51:55.549954 Training - batch 56/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3925 - accuracy: 0.8321 - val_loss: 0.3915 - val_accuracy: 0.8360\n",
      "2024-01-21 12:52:31.724440 Training - batch 57/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3929 - accuracy: 0.8285 - val_loss: 0.3791 - val_accuracy: 0.8390\n",
      "2024-01-21 12:53:07.979034 Training - batch 58/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3935 - accuracy: 0.8227 - val_loss: 0.3793 - val_accuracy: 0.8405\n",
      "2024-01-21 12:53:44.076918 Training - batch 59/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3888 - accuracy: 0.8326 - val_loss: 0.3974 - val_accuracy: 0.8290\n",
      "2024-01-21 12:54:20.466488 Training - batch 60/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3964 - accuracy: 0.8263 - val_loss: 0.3892 - val_accuracy: 0.8315\n",
      "2024-01-21 12:54:56.865522 Training - batch 61/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3857 - accuracy: 0.8317 - val_loss: 0.3732 - val_accuracy: 0.8480\n",
      "2024-01-21 12:55:33.198806 Training - batch 62/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3803 - accuracy: 0.8371 - val_loss: 0.3787 - val_accuracy: 0.8390\n",
      "2024-01-21 12:56:09.634578 Training - batch 63/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3922 - accuracy: 0.8300 - val_loss: 0.3901 - val_accuracy: 0.8360\n",
      "2024-01-21 12:56:46.073240 Training - batch 64/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3841 - accuracy: 0.8329 - val_loss: 0.4020 - val_accuracy: 0.8285\n",
      "2024-01-21 12:57:22.525034 Training - batch 65/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3808 - accuracy: 0.8379 - val_loss: 0.3743 - val_accuracy: 0.8350\n",
      "2024-01-21 12:57:58.959733 Training - batch 66/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3972 - accuracy: 0.8310 - val_loss: 0.3907 - val_accuracy: 0.8265\n",
      "2024-01-21 12:58:35.024609 Training - batch 67/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3812 - accuracy: 0.8407 - val_loss: 0.3967 - val_accuracy: 0.8270\n",
      "2024-01-21 12:59:11.293024 Training - batch 68/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3825 - accuracy: 0.8374 - val_loss: 0.3989 - val_accuracy: 0.8290\n",
      "2024-01-21 12:59:47.372421 Training - batch 69/71\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3777 - accuracy: 0.8454 - val_loss: 0.3806 - val_accuracy: 0.8410\n",
      "2024-01-21 13:00:23.485444 Training - batch 70/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3840 - accuracy: 0.8386 - val_loss: 0.4053 - val_accuracy: 0.8235\n",
      "2024-01-21 13:00:59.665273 Training - batch 71/71\n",
      "181/181 [==============================] - 35s 188ms/step - loss: 0.3953 - accuracy: 0.8348 - val_loss: 0.4137 - val_accuracy: 0.8328\n",
      "Epoch 2/2\n",
      "2024-01-21 13:01:34.987411 Training - batch 1/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3853 - accuracy: 0.8332 - val_loss: 0.3646 - val_accuracy: 0.8425\n",
      "2024-01-21 13:02:11.212600 Training - batch 2/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3757 - accuracy: 0.8441 - val_loss: 0.3879 - val_accuracy: 0.8420\n",
      "2024-01-21 13:02:47.388246 Training - batch 3/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3789 - accuracy: 0.8380 - val_loss: 0.3696 - val_accuracy: 0.8410\n",
      "2024-01-21 13:03:23.759307 Training - batch 4/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3879 - accuracy: 0.8351 - val_loss: 0.3948 - val_accuracy: 0.8295\n",
      "2024-01-21 13:04:00.240036 Training - batch 5/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3877 - accuracy: 0.8319 - val_loss: 0.3948 - val_accuracy: 0.8360\n",
      "2024-01-21 13:04:36.537326 Training - batch 6/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3810 - accuracy: 0.8384 - val_loss: 0.3856 - val_accuracy: 0.8410\n",
      "2024-01-21 13:05:12.871392 Training - batch 7/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3776 - accuracy: 0.8391 - val_loss: 0.3580 - val_accuracy: 0.8550\n",
      "2024-01-21 13:05:49.264881 Training - batch 8/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3864 - accuracy: 0.8355 - val_loss: 0.3751 - val_accuracy: 0.8435\n",
      "2024-01-21 13:06:25.561195 Training - batch 9/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3844 - accuracy: 0.8403 - val_loss: 0.3841 - val_accuracy: 0.8400\n",
      "2024-01-21 13:07:01.817691 Training - batch 10/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3688 - accuracy: 0.8440 - val_loss: 0.3812 - val_accuracy: 0.8390\n",
      "2024-01-21 13:07:38.327715 Training - batch 11/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3819 - accuracy: 0.8361 - val_loss: 0.3676 - val_accuracy: 0.8465\n",
      "2024-01-21 13:08:14.789101 Training - batch 12/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3793 - accuracy: 0.8451 - val_loss: 0.3963 - val_accuracy: 0.8265\n",
      "2024-01-21 13:08:51.037115 Training - batch 13/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3917 - accuracy: 0.8291 - val_loss: 0.3699 - val_accuracy: 0.8390\n",
      "2024-01-21 13:09:27.457153 Training - batch 14/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3724 - accuracy: 0.8470 - val_loss: 0.3892 - val_accuracy: 0.8280\n",
      "2024-01-21 13:10:03.660315 Training - batch 15/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3792 - accuracy: 0.8384 - val_loss: 0.3798 - val_accuracy: 0.8490\n",
      "2024-01-21 13:10:39.901187 Training - batch 16/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3801 - accuracy: 0.8390 - val_loss: 0.3705 - val_accuracy: 0.8490\n",
      "2024-01-21 13:11:16.366408 Training - batch 17/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3719 - accuracy: 0.8482 - val_loss: 0.3878 - val_accuracy: 0.8320\n",
      "2024-01-21 13:11:52.597960 Training - batch 18/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3937 - accuracy: 0.8313 - val_loss: 0.3669 - val_accuracy: 0.8505\n",
      "2024-01-21 13:12:28.963521 Training - batch 19/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3865 - accuracy: 0.8371 - val_loss: 0.3783 - val_accuracy: 0.8500\n",
      "2024-01-21 13:13:05.389644 Training - batch 20/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3833 - accuracy: 0.8339 - val_loss: 0.4070 - val_accuracy: 0.8265\n",
      "2024-01-21 13:13:41.796952 Training - batch 21/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3842 - accuracy: 0.8363 - val_loss: 0.3749 - val_accuracy: 0.8395\n",
      "2024-01-21 13:14:18.155534 Training - batch 22/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3807 - accuracy: 0.8393 - val_loss: 0.3687 - val_accuracy: 0.8410\n",
      "2024-01-21 13:14:54.582886 Training - batch 23/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3745 - accuracy: 0.8430 - val_loss: 0.3772 - val_accuracy: 0.8510\n",
      "2024-01-21 13:15:30.984336 Training - batch 24/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3775 - accuracy: 0.8419 - val_loss: 0.3871 - val_accuracy: 0.8385\n",
      "2024-01-21 13:16:07.498270 Training - batch 25/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3860 - accuracy: 0.8335 - val_loss: 0.3716 - val_accuracy: 0.8420\n",
      "2024-01-21 13:16:44.049296 Training - batch 26/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3644 - accuracy: 0.8480 - val_loss: 0.3882 - val_accuracy: 0.8320\n",
      "2024-01-21 13:17:20.631373 Training - batch 27/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3818 - accuracy: 0.8378 - val_loss: 0.3713 - val_accuracy: 0.8435\n",
      "2024-01-21 13:17:57.302386 Training - batch 28/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3692 - accuracy: 0.8451 - val_loss: 0.3788 - val_accuracy: 0.8425\n",
      "2024-01-21 13:18:34.094143 Training - batch 29/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3759 - accuracy: 0.8369 - val_loss: 0.3722 - val_accuracy: 0.8490\n",
      "2024-01-21 13:19:10.688694 Training - batch 30/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3814 - accuracy: 0.8407 - val_loss: 0.3772 - val_accuracy: 0.8355\n",
      "2024-01-21 13:19:47.133865 Training - batch 31/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3677 - accuracy: 0.8484 - val_loss: 0.3862 - val_accuracy: 0.8405\n",
      "2024-01-21 13:20:23.586857 Training - batch 32/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3749 - accuracy: 0.8401 - val_loss: 0.3791 - val_accuracy: 0.8375\n",
      "2024-01-21 13:21:00.089237 Training - batch 33/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3822 - accuracy: 0.8336 - val_loss: 0.3740 - val_accuracy: 0.8490\n",
      "2024-01-21 13:21:36.573313 Training - batch 34/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3802 - accuracy: 0.8435 - val_loss: 0.4017 - val_accuracy: 0.8220\n",
      "2024-01-21 13:22:13.000140 Training - batch 35/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3835 - accuracy: 0.8364 - val_loss: 0.3853 - val_accuracy: 0.8290\n",
      "2024-01-21 13:22:49.423708 Training - batch 36/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3615 - accuracy: 0.8510 - val_loss: 0.3767 - val_accuracy: 0.8435\n",
      "2024-01-21 13:23:26.058682 Training - batch 37/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3716 - accuracy: 0.8438 - val_loss: 0.3765 - val_accuracy: 0.8365\n",
      "2024-01-21 13:24:02.646709 Training - batch 38/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3665 - accuracy: 0.8459 - val_loss: 0.4001 - val_accuracy: 0.8255\n",
      "2024-01-21 13:24:39.137781 Training - batch 39/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3780 - accuracy: 0.8405 - val_loss: 0.3995 - val_accuracy: 0.8355\n",
      "2024-01-21 13:25:15.630180 Training - batch 40/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3696 - accuracy: 0.8476 - val_loss: 0.3929 - val_accuracy: 0.8250\n",
      "2024-01-21 13:25:52.125478 Training - batch 41/71\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3619 - accuracy: 0.8482 - val_loss: 0.3850 - val_accuracy: 0.8370\n",
      "2024-01-21 13:26:28.496546 Training - batch 42/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3666 - accuracy: 0.8480 - val_loss: 0.4072 - val_accuracy: 0.8220\n",
      "2024-01-21 13:27:05.125672 Training - batch 43/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3891 - accuracy: 0.8361 - val_loss: 0.3946 - val_accuracy: 0.8320\n",
      "2024-01-21 13:27:41.721086 Training - batch 44/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3692 - accuracy: 0.8485 - val_loss: 0.3863 - val_accuracy: 0.8360\n",
      "2024-01-21 13:28:18.335426 Training - batch 45/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3825 - accuracy: 0.8388 - val_loss: 0.3765 - val_accuracy: 0.8365\n",
      "2024-01-21 13:28:54.834682 Training - batch 46/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3699 - accuracy: 0.8419 - val_loss: 0.3907 - val_accuracy: 0.8440\n",
      "2024-01-21 13:29:31.539878 Training - batch 47/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3809 - accuracy: 0.8401 - val_loss: 0.3836 - val_accuracy: 0.8395\n",
      "2024-01-21 13:30:08.302584 Training - batch 48/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3849 - accuracy: 0.8349 - val_loss: 0.3706 - val_accuracy: 0.8380\n",
      "2024-01-21 13:30:44.834564 Training - batch 49/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3623 - accuracy: 0.8495 - val_loss: 0.3925 - val_accuracy: 0.8345\n",
      "2024-01-21 13:31:21.415821 Training - batch 50/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3803 - accuracy: 0.8394 - val_loss: 0.3799 - val_accuracy: 0.8355\n",
      "2024-01-21 13:31:57.850343 Training - batch 51/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3725 - accuracy: 0.8397 - val_loss: 0.3662 - val_accuracy: 0.8415\n",
      "2024-01-21 13:32:34.622843 Training - batch 52/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3741 - accuracy: 0.8407 - val_loss: 0.3939 - val_accuracy: 0.8385\n",
      "2024-01-21 13:33:11.408306 Training - batch 53/71\n",
      "250/250 [==============================] - 36s 146ms/step - loss: 0.3726 - accuracy: 0.8397 - val_loss: 0.3711 - val_accuracy: 0.8410\n",
      "2024-01-21 13:33:47.924211 Training - batch 54/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3755 - accuracy: 0.8426 - val_loss: 0.3723 - val_accuracy: 0.8440\n",
      "2024-01-21 13:34:24.542068 Training - batch 55/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3660 - accuracy: 0.8449 - val_loss: 0.3875 - val_accuracy: 0.8295\n",
      "2024-01-21 13:35:01.173430 Training - batch 56/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3783 - accuracy: 0.8378 - val_loss: 0.3856 - val_accuracy: 0.8370\n",
      "2024-01-21 13:35:37.918370 Training - batch 57/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3747 - accuracy: 0.8418 - val_loss: 0.3706 - val_accuracy: 0.8460\n",
      "2024-01-21 13:36:14.626659 Training - batch 58/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3770 - accuracy: 0.8351 - val_loss: 0.3750 - val_accuracy: 0.8430\n",
      "2024-01-21 13:36:51.419004 Training - batch 59/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3748 - accuracy: 0.8399 - val_loss: 0.3859 - val_accuracy: 0.8380\n",
      "2024-01-21 13:37:28.154329 Training - batch 60/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3810 - accuracy: 0.8336 - val_loss: 0.3780 - val_accuracy: 0.8380\n",
      "2024-01-21 13:38:04.773950 Training - batch 61/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3687 - accuracy: 0.8413 - val_loss: 0.3643 - val_accuracy: 0.8525\n",
      "2024-01-21 13:38:41.608787 Training - batch 62/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3647 - accuracy: 0.8445 - val_loss: 0.3687 - val_accuracy: 0.8390\n",
      "2024-01-21 13:39:18.491215 Training - batch 63/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3793 - accuracy: 0.8386 - val_loss: 0.3826 - val_accuracy: 0.8375\n",
      "2024-01-21 13:39:55.189791 Training - batch 64/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3719 - accuracy: 0.8414 - val_loss: 0.3942 - val_accuracy: 0.8290\n",
      "2024-01-21 13:40:31.995231 Training - batch 65/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3683 - accuracy: 0.8453 - val_loss: 0.3699 - val_accuracy: 0.8400\n",
      "2024-01-21 13:41:08.663219 Training - batch 66/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3819 - accuracy: 0.8394 - val_loss: 0.3792 - val_accuracy: 0.8335\n",
      "2024-01-21 13:41:45.411567 Training - batch 67/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3688 - accuracy: 0.8503 - val_loss: 0.3921 - val_accuracy: 0.8300\n",
      "2024-01-21 13:42:22.022747 Training - batch 68/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3670 - accuracy: 0.8470 - val_loss: 0.3955 - val_accuracy: 0.8350\n",
      "2024-01-21 13:42:58.582367 Training - batch 69/71\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3642 - accuracy: 0.8519 - val_loss: 0.3705 - val_accuracy: 0.8475\n",
      "2024-01-21 13:43:35.241559 Training - batch 70/71\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3669 - accuracy: 0.8441 - val_loss: 0.3930 - val_accuracy: 0.8290\n",
      "2024-01-21 13:44:12.050780 Training - batch 71/71\n",
      "181/181 [==============================] - 34s 190ms/step - loss: 0.3810 - accuracy: 0.8418 - val_loss: 0.4036 - val_accuracy: 0.8314\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "\n",
    "for j in range(n_epochs):\n",
    "    print(f\"Epoch {j+1}/{n_epochs}\")\n",
    "    for i in range(n_batch0_train):\n",
    "        print(f\"{datetime.datetime.now()} Training - batch {i+1}/{n_batch0_train}\")\n",
    "        with open(f\"{path_out_x_train}x_{i}.pickle\",\"rb\") as f:\n",
    "            x_train_batch = pickle.load(f)\n",
    "        with open(f\"{path_out_y_train}y_{i}.pickle\",\"rb\") as f:\n",
    "            y_train_batch = pickle.load(f)\n",
    "        model.fit(x_train_batch, y_train_batch, batch_size=batch_size,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c019163c-717a-441b-b790-0ea882bf15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(os.path.exists('model/')):\n",
    "    os.mkdir('model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63835d55-10fd-4d77-b2fe-149aa19ecccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/lstm.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "453d7a58-b404-4b28-89e6-8fc3a1cab759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-21 14:14:51.609102 Prediction - test set - batch 1/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:15:12.472782 Prediction - test set - batch 2/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:15:32.975791 Prediction - test set - batch 3/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:15:53.479122 Prediction - test set - batch 4/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:16:13.989475 Prediction - test set - batch 5/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:16:34.495553 Prediction - test set - batch 6/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:16:55.003852 Prediction - test set - batch 7/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:17:15.502587 Prediction - test set - batch 8/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:17:36.002733 Prediction - test set - batch 9/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:17:56.506687 Prediction - test set - batch 10/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:18:17.007386 Prediction - test set - batch 11/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:18:37.513027 Prediction - test set - batch 12/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:18:58.023080 Prediction - test set - batch 13/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:19:09.905429 Prediction - test set - batch 14/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:19:30.406035 Prediction - test set - batch 15/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:19:50.906045 Prediction - test set - batch 16/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:20:11.406072 Prediction - test set - batch 17/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:20:31.906390 Prediction - test set - batch 18/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:20:52.415042 Prediction - test set - batch 19/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:21:12.914045 Prediction - test set - batch 20/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:21:33.414388 Prediction - test set - batch 21/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:21:53.915028 Prediction - test set - batch 22/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:22:14.415415 Prediction - test set - batch 23/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:22:34.914695 Prediction - test set - batch 24/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:22:55.424155 Prediction - test set - batch 25/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:23:15.923276 Prediction - test set - batch 26/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:23:36.424540 Prediction - test set - batch 27/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:23:56.925330 Prediction - test set - batch 28/31\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:24:17.427565 Prediction - test set - batch 29/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:24:37.930107 Prediction - test set - batch 30/31\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:24:58.440215 Prediction - test set - batch 31/31\n",
      "97/97 [==============================] - 4s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "prob_pred_test_batch = []\n",
    "\n",
    "for i in range(n_batch0_test):\n",
    "    print(f\"{datetime.datetime.now()} Prediction - test set - batch {i+1}/{n_batch0_test}\")\n",
    "    with open(f\"{path_out_x_test}x_{i}.pickle\",\"rb\") as f:\n",
    "        x_test_batch = pickle.load(f)\n",
    "    prob_pred_test_batch.append(model.predict(x_test_batch))\n",
    "\n",
    "prob_pred_test = np.concatenate(prob_pred_test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28ef1cb8-5c45-468b-8b4d-40242905e558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-21 14:27:54.826148 Prediction - train set - batch 1/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:28:15.325327 Prediction - train set - batch 2/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:28:35.824735 Prediction - train set - batch 3/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:28:56.327766 Prediction - train set - batch 4/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:29:08.054341 Prediction - train set - batch 5/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:29:28.554949 Prediction - train set - batch 6/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:29:40.321505 Prediction - train set - batch 7/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:29:52.063032 Prediction - train set - batch 8/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:30:12.562835 Prediction - train set - batch 9/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:30:33.063469 Prediction - train set - batch 10/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:30:53.569436 Prediction - train set - batch 11/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:31:14.075699 Prediction - train set - batch 12/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:31:34.577268 Prediction - train set - batch 13/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:31:55.076716 Prediction - train set - batch 14/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:32:15.577183 Prediction - train set - batch 15/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:32:36.078668 Prediction - train set - batch 16/71\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:32:56.580780 Prediction - train set - batch 17/71\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:33:17.087555 Prediction - train set - batch 18/71\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:33:37.588943 Prediction - train set - batch 19/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:33:49.361560 Prediction - train set - batch 20/71\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:34:09.862403 Prediction - train set - batch 21/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:34:21.632261 Prediction - train set - batch 22/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:34:33.386799 Prediction - train set - batch 23/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:34:53.892380 Prediction - train set - batch 24/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:35:14.395578 Prediction - train set - batch 25/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:35:34.894152 Prediction - train set - batch 26/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:35:55.395061 Prediction - train set - batch 27/71\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:36:15.896490 Prediction - train set - batch 28/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:36:36.396806 Prediction - train set - batch 29/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:36:48.156093 Prediction - train set - batch 30/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:37:08.657945 Prediction - train set - batch 31/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:37:29.157231 Prediction - train set - batch 32/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:37:49.657729 Prediction - train set - batch 33/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:38:10.158650 Prediction - train set - batch 34/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:38:30.659190 Prediction - train set - batch 35/71\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:38:51.164761 Prediction - train set - batch 36/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:39:11.667399 Prediction - train set - batch 37/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:39:23.441872 Prediction - train set - batch 38/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:39:35.177196 Prediction - train set - batch 39/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:39:55.678062 Prediction - train set - batch 40/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:40:16.183377 Prediction - train set - batch 41/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:40:36.688276 Prediction - train set - batch 42/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:40:57.191072 Prediction - train set - batch 43/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:41:17.692164 Prediction - train set - batch 44/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:41:38.193262 Prediction - train set - batch 45/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:41:58.694294 Prediction - train set - batch 46/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:42:19.199982 Prediction - train set - batch 47/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:42:39.705031 Prediction - train set - batch 48/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:43:00.205126 Prediction - train set - batch 49/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:43:20.707444 Prediction - train set - batch 50/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:43:41.208436 Prediction - train set - batch 51/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:44:01.709549 Prediction - train set - batch 52/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:44:22.208828 Prediction - train set - batch 53/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:44:33.936505 Prediction - train set - batch 54/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:44:54.436697 Prediction - train set - batch 55/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:45:14.937950 Prediction - train set - batch 56/71\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:45:35.438247 Prediction - train set - batch 57/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:45:55.939361 Prediction - train set - batch 58/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:46:07.713408 Prediction - train set - batch 59/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:46:19.442527 Prediction - train set - batch 60/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:46:31.203644 Prediction - train set - batch 61/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:46:51.703984 Prediction - train set - batch 62/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:47:12.204553 Prediction - train set - batch 63/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:47:32.704800 Prediction - train set - batch 64/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:47:44.439393 Prediction - train set - batch 65/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:47:56.190815 Prediction - train set - batch 66/71\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:48:16.689855 Prediction - train set - batch 67/71\n",
      "313/313 [==============================] - 12s 38ms/step\n",
      "2024-01-21 14:48:37.191810 Prediction - train set - batch 68/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:48:57.692271 Prediction - train set - batch 69/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:49:18.192818 Prediction - train set - batch 70/71\n",
      "313/313 [==============================] - 12s 37ms/step\n",
      "2024-01-21 14:49:38.693462 Prediction - train set - batch 71/71\n",
      "226/226 [==============================] - 8s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "prob_pred_train_batch = []\n",
    "\n",
    "for i in range(n_batch0_train):\n",
    "    print(f\"{datetime.datetime.now()} Prediction - train set - batch {i+1}/{n_batch0_train}\")\n",
    "    with open(f\"{path_out_x_train}x_{i}.pickle\",\"rb\") as f:\n",
    "        x_train_batch = pickle.load(f)\n",
    "    prob_pred_train_batch.append(model.predict(x_train_batch))\n",
    "\n",
    "prob_pred_train = np.concatenate(prob_pred_train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a951051-b3cf-4ddc-a327-36e251947058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.8272466018370601, 'test': 0.8080723495763509}\n"
     ]
    }
   ],
   "source": [
    "AUC = {\n",
    "       'train': roc_auc_score(y_train,prob_pred_train),\n",
    "       'test': roc_auc_score(y_test,prob_pred_test),\n",
    "       }\n",
    "\n",
    "print(AUC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
